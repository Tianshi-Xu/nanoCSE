#!/usr/bin/env python3
"""
SE Operators Base Classes

å®šä¹‰äº†æ‰€æœ‰ç®—å­çš„åŸºç±»å’Œæ ¸å¿ƒæ¥å£ã€‚
ç®—å­æ˜¯æ¨¡å—åŒ–çš„ã€å¯é‡ç”¨çš„ç»„ä»¶ï¼Œç”¨äºæ‰§è¡Œç‰¹å®šçš„è½¨è¿¹æ“ä½œï¼Œå¦‚ç”Ÿæˆã€äº¤å‰æˆ–è¿‡æ»¤ã€‚
"""

from __future__ import annotations

import abc
import random
import re
from dataclasses import dataclass, field
from typing import Any

from core.utils.llm_client import LLMClient
from core.utils.se_logger import get_se_logger
from core.utils.traj_pool_manager import TrajPoolManager
from perf_config import StepConfig


# ---------------------------------------------------------------------------
# æ•°æ®ç»“æ„
# ---------------------------------------------------------------------------


@dataclass
class OperatorContext:
    """ç®—å­æ‰§è¡Œçš„å…±äº«ä¸Šä¸‹æ–‡ã€‚

    å°è£…ç®—å­æ‰€éœ€çš„æ¨¡å‹é…ç½®ã€æç¤ºè¯é…ç½®å’Œé€‰æ‹©æ¨¡å¼ï¼Œ
    æ›¿ä»£åŸå…ˆé€šè¿‡ dict ä¼ é€’çš„ operator_configã€‚

    Attributes:
        model_config: LLM æ¨¡å‹é…ç½®ï¼ˆä¿ç•™ dictï¼Œå› ä¸ºéœ€é€ä¼ ç»™ LLMClientï¼‰ã€‚
        prompt_config: æç¤ºè¯é…ç½®ã€‚
        selection_mode: é»˜è®¤è½¨è¿¹é€‰æ‹©æ¨¡å¼ï¼ˆ"weighted" æˆ– "random"ï¼‰ã€‚
    """

    model_config: dict[str, Any] = field(default_factory=dict)
    prompt_config: dict[str, Any] = field(default_factory=dict)
    selection_mode: str = "weighted"


@dataclass
class OperatorResult:
    """å•å®ä¾‹ç®—å­æ‰§è¡Œç»“æœ

    è¿™æ˜¯ Operator è¿”å›ç»™ perf_run.py çš„æ ‡å‡†åŒ–ç»“æœå¯¹è±¡ã€‚
    åŒ…å«ç”¨äºæ„å»º PerfAgentRequest çš„å…¨éƒ¨ä¿¡æ¯ã€‚

    Attributes:
        additional_requirements: é¢å¤–çš„ prompt è¦æ±‚ï¼ˆæ¥è‡ªç®—å­åˆ†æï¼‰
        initial_code: å¯é€‰çš„åˆå§‹ä»£ç è¦†ç›–
        source_labels: ä½¿ç”¨çš„æºè½¨è¿¹æ ‡ç­¾åˆ—è¡¨
    """

    additional_requirements: str | None = None
    initial_code: str | None = None
    source_labels: list[str] = field(default_factory=list)


# ---------------------------------------------------------------------------
# åŸºç±»
# ---------------------------------------------------------------------------


class BaseOperator(abc.ABC):
    """
    SEç®—å­åŸºç±»ï¼Œå®šä¹‰é€šç”¨åŠŸèƒ½å’Œæ–°çš„ `run` æ¥å£ã€‚
    æ‰€æœ‰ç®—å­éƒ½åº”ç»§æ‰¿è‡ªæ­¤ç±»ã€‚
    """

    def __init__(self, context: OperatorContext):
        """
        åˆå§‹åŒ–ç®—å­ã€‚

        Args:
            context: OperatorContext å®ä¾‹ã€‚
        """
        self.context = context
        self.llm_client: LLMClient | None = None
        self.logger = get_se_logger(f"operator.{self.get_name()}", emoji="ğŸ”§")

    def _setup_model(self) -> None:
        """è®¾ç½®LLMå®¢æˆ·ç«¯å®ä¾‹ã€‚"""
        if self.llm_client is not None:
            return
        model_config_data = self.context.model_config
        self.llm_client = LLMClient(model_config_data)
        self.logger.info(f"LLMå®¢æˆ·ç«¯å·²åˆå§‹åŒ–: {model_config_data.get('name')}")

    def _call_llm_api(self, prompt: str, system_prompt: str = "") -> str:
        """
        è°ƒç”¨LLM APIã€‚

        Args:
            prompt: ç”¨æˆ·æç¤ºã€‚
            system_prompt: ç³»ç»Ÿæç¤ºã€‚

        Returns:
            LLMç”Ÿæˆçš„å“åº”æ–‡æœ¬ã€‚
        """
        self._setup_model()
        history = []
        if system_prompt:
            history.append({"role": "system", "content": system_prompt})
        history.append({"role": "user", "content": prompt})

        try:
            model_cfg = self.context.model_config
            temp = model_cfg.get("temperature", 0.3)
            max_out = model_cfg.get("max_output_tokens")
            self.logger.debug(f"LLMç³»ç»Ÿæç¤ºè¯:\n{system_prompt}")
            self.logger.debug(f"LLMç”¨æˆ·æç¤ºè¯:\n{prompt}")
            message = self.llm_client.call_llm(
                history,
                temperature=temp,
                max_tokens=max_out,
                usage_context=f"operator.{self.get_name()}",
            )
            self.logger.debug(f"LLMåŸå§‹å“åº”:\n{message}")
            if message:
                message = self.llm_client.clean_think_tags(message)
            self.logger.debug(f"LLMæ¸…ç†åå“åº”:\n{message}")
            return message or ""
        except Exception as e:
            self.logger.error(f"LLM APIè°ƒç”¨å¤±è´¥: {e}")
            return ""

    def _extract_code_block_py(self, text: str) -> str | None:
        """ä»LLMè¾“å‡ºä¸­æå– ```py ... ``` ä»£ç å—å†…å®¹ã€‚"""
        if not isinstance(text, str) or not text:
            return None
        pattern = re.compile(r"```(?:py|python)\s*\n(.*?)\n```", re.DOTALL | re.IGNORECASE)
        m = pattern.search(text)
        if m:
            return m.group(1).strip() or None
        return None

    def _extract_code_text(self, text: str) -> str | None:
        """ä¼˜å…ˆæå–ä»£ç å—ï¼Œå¦åˆ™è¿”å›åŸå§‹æ–‡æœ¬å¹¶å°è¯•æ¸…ç†ã€‚"""
        if not isinstance(text, str) or not text.strip():
            return None
        block = self._extract_code_block_py(text)
        if isinstance(block, str) and block.strip():
            return block.strip()

        raw_code = text.strip()
        if raw_code.startswith("```") and raw_code.endswith("```"):
            try:
                raw_code = re.sub(r"^```(?:py|python)?\s*\n?", "", raw_code, flags=re.IGNORECASE)
                raw_code = re.sub(r"\n?```$", "", raw_code)
            except Exception:
                pass
        return raw_code.strip() or None

    def _require_py_block_with_retry(
        self,
        build_prompt_fn,
        max_retries: int = 2,
        temperature_override: float | None = None,
    ) -> str | None:
        """è¦æ±‚LLMä»¥```pyä»£ç å—```è¾“å‡ºï¼Œè‹¥æœªæ»¡è¶³åˆ™é‡è¯•ã€‚"""
        self._setup_model()
        model_cfg = self.context.model_config
        base_temp = model_cfg.get("temperature", 0.3)
        temp_to_use = base_temp if temperature_override is None else temperature_override

        for attempt in range(max_retries + 1):
            try:
                prompt, system_prompt = build_prompt_fn(attempt)
                pcfg = self.context.prompt_config or {}
                common = pcfg.get("base_operator", {}) if isinstance(pcfg.get("base_operator"), dict) else {}
                enforce_tail = common.get(
                    "enforce_tail",
                    pcfg.get(
                        "operator_enforce_tail",
                        "\n\nSTRICT FORMAT: Wrap the entire solution inside a fenced code block starting with ```py and ending with ```.",
                    ),
                )
                import_blocks = common.get(
                    "imports_block",
                    pcfg.get(
                        "operator_imports_block",
                        """\n\nAllowed Imports Scope: You may only import libraries within the scope defined below.
```python
import re
from re import match, search, sub, split, findall, finditer
import sys
from sys import maxsize, stdin
import json
from json import loads
import math
from math import floor, ceil, factorial, sqrt, isqrt, inf, log2, log10, sin, cos, tan, pi, e, comb, perm, gcd, lcm
import copy
import pickle
import heapq
from heapq import heappush, heappop, heapify, heappushpop, nlargest, nsmallest
import bisect
from bisect import bisect_left, bisect_right
import string
from string import ascii_letters, ascii_lowercase, ascii_uppercase, digits, whitespace, punctuation, hexdigits
import random
import operator
import itertools
from itertools import combinations, permutations, product, groupby, chain, accumulate, zip_longest
import functools
from functools import lru_cache, cache, reduce
import collections
from collections import OrderedDict, defaultdict, Counter, deque
from typing import Set, Dict, List, Optional, Tuple
import sortedcontainers # pip install sortedcontainers
from sortedcontainers import SortedList, SortedDict, SortedSet
```""",
                    ),
                )
                optimization_target = common.get(
                    "optimization_target",
                    pcfg.get(
                        "operator_optimization_target",
                        """
CORE TASK
Your task is to iteratively improve a given program in python for the problem described below, aiming to increase its **runtime**.

GUIDING PRINCEPLES
Your core philosophy is **CORRECTNESS FIRST, THEN PERFORMANCE**.
1.  **Correctness Priority**: Your primary goal is to produce correct outputs for all required cases. Ensure any changes maintain or improve correctness *before* optimizing for performance.
2.  **Performance Focus**: Improve performance only *after* correctness is assured. Prefer algorithmic improvements over micro-optimizations.
3.  **Context Utilization**: You MUST leverage all provided information (evolution history in the chat, current metrics, artifacts etc.) to make informed optimization decisions.
4.  **Substantial Impact**: Focus on meaningful improvements that significantly impact the fitness score.
5.  **Code Quality**: Keep the code readable, robust, and maintainable. Avoid unnecessary refactors.
6.  **Diversity**: Explore alternative algorithms, data structures, or techniques (e.g., built-in operators, packages) when appropriate.
                        """,
                    ),
                )
                system_prompt_use = system_prompt or ""
                if isinstance(enforce_tail, str) and enforce_tail.strip():
                    system_prompt_use += enforce_tail
                if isinstance(import_blocks, str) and import_blocks.strip():
                    system_prompt_use += import_blocks
                if isinstance(optimization_target, str) and optimization_target.strip():
                    system_prompt_use += optimization_target

                history = [{"role": "system", "content": system_prompt_use}, {"role": "user", "content": prompt}]
                max_out = model_cfg.get("max_output_tokens")
                enable_thinking = None if attempt == 0 else False

                self.logger.info(f"ç¬¬{attempt + 1}æ¬¡å°è¯•ï¼Œæ¸©åº¦={temp_to_use}")
                self.logger.debug(f"LLMç³»ç»Ÿæç¤ºè¯(é‡è¯•ç¬¬{attempt + 1}æ¬¡)")
                self.logger.debug(f"LLMç”¨æˆ·æç¤ºè¯(é‡è¯•ç¬¬{attempt + 1}æ¬¡)")

                message = self.llm_client.call_llm(
                    history,
                    temperature=temp_to_use,
                    max_tokens=max_out,
                    enable_thinking=enable_thinking,
                    usage_context=f"operator.{self.get_name()}",
                )
                self.logger.debug(f"LLMåŸå§‹å“åº”(é‡è¯•ç¬¬{attempt + 1}æ¬¡):\n{message}")
                if message:
                    message = self.llm_client.clean_think_tags(message)
                # self.logger.debug(f"LLMæ¸…ç†åå“åº”(é‡è¯•ç¬¬{attempt + 1}æ¬¡):\n{message}")

                code = self._extract_code_block_py(message or "")
                if code:
                    return code

                self.logger.warning("æœªæ£€æµ‹åˆ°```pyä»£ç å—ï¼Œè¿›è¡Œé‡è¯•")
            except Exception as e:
                self.logger.error(f"æ ¼å¼åŒ–ä»£ç å—ç”Ÿæˆå¤±è´¥: {e}")
                continue
        return None

    def _format_entry(self, approaches_data: dict[str, Any]) -> str:
        return TrajPoolManager.format_entry(approaches_data)

    def _weighted_select_labels(
        self, entry: dict[str, Any], k: int = 1, allowed_labels: list[str] | None = None
    ) -> list[str]:
        """åŸºäº performance çš„çº¿æ€§åŠ æƒé‡‡æ ·é€‰æ‹©å­æ ‡ç­¾ï¼Œperformance è¶Šä½æƒé‡è¶Šé«˜ã€‚
        è‹¥æä¾› allowed_labelsï¼Œåˆ™ä»…åœ¨è¯¥é›†åˆä¸­è¿›è¡Œé‡‡æ ·ï¼ˆå¿½ç•¥ä¸å­˜åœ¨çš„æ ‡ç­¾ï¼‰ã€‚
        """
        if not isinstance(entry, dict):
            return []
        items: list[tuple[str, float]] = []
        for subkey, subval in entry.items():
            if subkey == "problem" or not isinstance(subval, dict):
                continue
            if allowed_labels is not None:
                lab = str(subkey)
                lab2 = str(subval.get("label")) if isinstance(subval.get("label"), str) else None
                if lab not in allowed_labels and (lab2 is None or lab2 not in allowed_labels):
                    continue
            perf = subval.get("performance")
            try:
                perf_val = float(perf) if perf is not None else 1.0
            except Exception:
                perf_val = 1.0
            items.append((str(subkey), perf_val))
        if not items:
            return []
        eps = 1e-9
        selected: list[str] = []
        remaining = items.copy()
        for _ in range(min(k, len(remaining))):
            weights = [max(0.001, 1.0 / max(eps, perf)) for _, perf in remaining]
            total = sum(weights)
            if total <= 0:
                choice = random.choice(remaining)[0]
            else:
                weights = [w / total for w in weights]
                r = random.random()
                s = 0.0
                choice = remaining[-1][0]
                for (label_key, perf), w in zip(remaining, weights):
                    s += w
                    if r <= s:
                        choice = label_key
                        break
            selected.append(choice)
            remaining = [it for it in remaining if it[0] != choice]
        return selected

    def _random_select_labels(
        self, entry: dict[str, Any], k: int = 1, allowed_labels: list[str] | None = None
    ) -> list[str]:
        if not isinstance(entry, dict):
            return []
        candidates: list[str] = []
        for subkey, subval in entry.items():
            if subkey == "problem" or not isinstance(subval, dict):
                continue
            if allowed_labels is not None:
                lab = str(subkey)
                lab2 = str(subval.get("label")) if isinstance(subval.get("label"), str) else None
                if lab not in allowed_labels and (lab2 is None or lab2 not in allowed_labels):
                    continue
            candidates.append(str(subkey))
        if not candidates:
            return []
        k = min(k, len(candidates))
        try:
            return random.sample(candidates, k)
        except Exception:
            out: list[str] = []
            pool = candidates.copy()
            for _ in range(k):
                choice = random.choice(pool)
                out.append(choice)
                pool = [c for c in pool if c != choice]
                if not pool:
                    break
            return out

    def _get_selection_mode(self, step_config: StepConfig) -> str:
        try:
            v = step_config.selection_mode
            if isinstance(v, str) and v.strip():
                m = v.strip().lower()
                if m in ("weighted", "random"):
                    return m
            g = self.context.selection_mode
            if isinstance(g, str) and g.strip():
                m = g.strip().lower()
                if m in ("weighted", "random"):
                    return m
        except Exception:
            pass
        return "weighted"

    def _resolve_label_subkey(self, entry: dict[str, Any], label: str) -> str | None:
        """å°†å¤–éƒ¨æä¾›çš„æ ‡ç­¾è§£æä¸º entry çš„å­é”®ã€‚
        ä¼˜å…ˆåŒ¹é…å­é”®åï¼Œå…¶æ¬¡åŒ¹é…å­é¡¹å†…éƒ¨çš„ `label` å­—æ®µã€‚
        """
        if not isinstance(entry, dict):
            return None
        lab = str(label)
        if lab in entry and isinstance(entry.get(lab), dict):
            return lab
        for subkey, subval in entry.items():
            if subkey == "problem" or not isinstance(subval, dict):
                continue
            if str(subval.get("label")) == lab:
                return str(subkey)
        return None

    def _select_source_labels(self, entry: dict[str, Any], step_config: StepConfig, required_n: int) -> list[str]:
        """ç»Ÿä¸€é€‰æ‹©æºè½¨è¿¹æ ‡ç­¾ã€‚
        è§„åˆ™ï¼š
        - è‹¥ `inputs` æ ‡ç­¾æ•°ç›® == required_nï¼šç›´æ¥ä½¿ç”¨ `inputs`
        - è‹¥ `inputs` æ ‡ç­¾æ•°ç›® >  required_nï¼šåœ¨ `inputs` èŒƒå›´å†…åŠ æƒé‡‡æ · required_n ä¸ª
        - è‹¥ `inputs` æ ‡ç­¾æ•°ç›® <  required_nï¼šå…ˆä½¿ç”¨å·²æœ‰ `inputs`ï¼Œå‰©ä½™ä»æ•´ä¸ª entry ä¸­åŠ æƒé‡‡æ ·è¡¥é½
        è¿”å› entry å­é”®ååˆ—è¡¨ï¼Œå”¯ä¸€ä¸”æœ€å¤š required_n ä¸ªã€‚
        """
        if not isinstance(entry, dict):
            return []
        inputs = step_config.inputs or []
        provided_labels = [str(i.get("label")) for i in inputs if isinstance(i, dict) and i.get("label")]
        # è§£æä¸º entry å­é”®
        resolved = []
        seen = set()
        for lab in provided_labels:
            subkey = self._resolve_label_subkey(entry, lab)
            if subkey and subkey not in seen:
                resolved.append(subkey)
                seen.add(subkey)

        need = max(0, int(required_n))
        count = len(resolved)
        if count == need:
            return resolved
        if count > need:
            mode = self._get_selection_mode(step_config)
            if mode == "random":
                sampled = self._random_select_labels(entry, k=need, allowed_labels=resolved)
            else:
                sampled = self._weighted_select_labels(entry, k=need, allowed_labels=resolved)
            # å»é‡å¹¶è¿”å›
            out = []
            used = set()
            for s in sampled:
                if s not in used:
                    out.append(s)
                    used.add(s)
            return out

        # count < needï¼šå…ˆç”¨å·²æœ‰ï¼Œå†è¡¥é½
        out = list(resolved)
        used = set(out)
        # æ„å»ºå€™é€‰é›†åˆï¼ˆæ’é™¤å·²é€‰ï¼‰
        all_subkeys = [str(k) for k, v in entry.items() if k != "problem" and isinstance(v, dict)]
        remaining = [k for k in all_subkeys if k not in used]
        if remaining:
            mode = self._get_selection_mode(step_config)
            if mode == "random":
                sampled_more = self._random_select_labels(entry, k=need - count, allowed_labels=remaining)
            else:
                sampled_more = self._weighted_select_labels(entry, k=need - count, allowed_labels=remaining)
            for s in sampled_more:
                if s not in used:
                    out.append(s)
                    used.add(s)
                if len(out) >= need:
                    break
        return out[:need]

    @abc.abstractmethod
    def get_name(self) -> str:
        """è·å–ç®—å­åç§°ã€‚"""
        pass

    @abc.abstractmethod
    def run_for_instance(
        self,
        step_config: StepConfig,
        instance_name: str,
        instance_entry: dict[str, Any],
    ) -> OperatorResult:
        """å¤„ç†å•ä¸ªå®ä¾‹ï¼Œè¿”å›ç»“æ„åŒ–ç»“æœã€‚

        è¿™æ˜¯å•å®ä¾‹æ¨¡å¼ä¸‹çš„æ ‡å‡†è°ƒç”¨æ¥å£ã€‚å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•ã€‚

        Args:
            step_config: å½“å‰æ­¥éª¤çš„é…ç½®ï¼ˆStepConfig å¯¹è±¡ï¼‰ã€‚
            instance_name: å®ä¾‹åç§°ã€‚
            instance_entry: è¯¥å®ä¾‹åœ¨è½¨è¿¹æ± ä¸­çš„æ•°æ®å­—å…¸ã€‚

        Returns:
            OperatorResult å¯¹è±¡ï¼ŒåŒ…å« additional_requirementsã€initial_code ç­‰ã€‚
        """
        ...


class TemplateOperator(BaseOperator):
    """
    æ¨¡æ¿ç®—å­åŸºç±»ï¼Œç”¨äºä¸ºä¸‹ä¸€æ¬¡ PerfAgent è¿è¡Œç”Ÿæˆåˆå§‹ä»£ç ã€‚
    """


class EnhanceOperator(BaseOperator):
    """
    å¢å¼ºç®—å­åŸºç±»ï¼Œç”¨äºä¸ºä¸‹ä¸€æ¬¡ PerfAgent è¿è¡Œç”Ÿæˆå¢å¼ºå†å²é…ç½®ã€‚
    """
